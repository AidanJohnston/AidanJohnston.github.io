---
layout: post
title: OpenCL Neural Network for Detecting Cats & Dogs
tags: Python OpenCL NN Jupyter-Notebook Classification
---

Implementation of a neural network using opencl to detect cats and dogs.

# Python Training

## Preprocessing

Before any preprocessing can take place, the images must be loaded into the python runtime. The folders containing the images must first be unzipped, and then the files in each can be loaded and appropriately preprocessed. The images are first loaded, then immediately converted to grayscale. They are then resized in a 16x16 image and converted into an array.

<p align="center">
<img src="https://imgur.com/d0iO0GE.png">
</p>

<p align="center">
<img src="https://imgur.com/nrugMB2.png">
</p>

<p align="center">
<img src="https://imgur.com/8klcTTT.png">
</p>

<p align="center">
<img src="https://imgur.com/SSINGX9.png">
</p>

This 2D array must then be flattened into a 1D array, followed by dividing the values in the array by 255 in order to normalize them between 0 and 1 for better neural net performance. This resulting array is put into the xData list, and the yData list receives a 1 or 0 depending on the type of animal that the picture is. Finally, the xData and yData lists are shuffled and split into Training Validation,and Testing sets, 70% 15% and 15% respectively.

<p align="center">
<img src="https://imgur.com/mbUkg4w.png">
</p>

Additional preprocessing could involve removing bad data such as pictures of humans or buildings from the dataset as the model is not supposed to be trained on them, however the number of bad images is relatively small so the impact on the accuracy of the model is most likely minimal.

## Model Design

The two main factors that affected the design of the model were prediction accuracy and number of parameters. Prediction accuracy should obviously always be as high as possible, while the number of parameters needed to be kept below a certain threshold in this case in order to have the OpenCL implementation fit within the memory constraints of a FPGA board. Since the input layer has 256 values in it, the two hidden layers needed to be of a small enough size in order to keep the number of parameters low enough while still being able to accurately classify the image. We chose hidden layer sizes of 25 and 16, as these values kept the number of parameters below the threshold while still giving a good accuracy.

<p align="center">
<img src="https://imgur.com/fnnTZAB.png">
</p>

The Sigmoid activation function was used for the final 1-node output layer, as its results are smoothly bounded between 0 and 1 which is incredibly helpful for this task.

The two hidden layers use the Swish activation function, which is defined as swish(x)=xsigmoid(x). Swish is an activation function created by Google, and is very similar to Relu except it tends to result in models with higher accuracies. It is characterized by its one-sided boundedness at zero, smoothness, and non-monotonicity.

## Model Training

Binary Crossentropy was initially chosen as the loss function for training due to the fact that it is designed for binary classification, however it began killing neurons at around 80 epochs and would permanently drop the accuracy to around 50% at that point. To fix this issue, Mean Squared Error was used as the loss function instead.

<p align="center">
<img src="https://imgur.com/tXV1ZLG.png">
</p>

<p align="center">
<img src="https://imgur.com/6HXZaMP.png">
</p>

Various different learning rate and momentum values were tested, however it was found that 0.03 and 0.3 respectively were able to produce a decent loss and accuracy for the model. These values could be optimized further, however for the purposes of this project they are acceptable.

After some experimentation, it was found that the most efficient number of epochs to train was 100. Values lower would result in the model not reaching its maximum potential accuracy, and a higher value would cause the model to overfit and lose accuracy once more.

In order to reduce the speed at which the model overfit itself, K-fold cross validation was performed using various different batch sizes. After some testing, it was found that a batch size of n/16 (16-fold cross validation) was the most effective. With all of these techniques being used, our model achieved a peak validation accuracy of 65% and a testing accuracy of 63.5%.

## Model Export

After the model had been successfully trained, the weights and biases had to be exported to a file in order to be read by the OpenCL host program. In order to do this, the weights were converted into a 2D array and printed to a .csv file.

<p align="center">
<img src="https://imgur.com/8FzrkZ7.png">
</p>

# OpenCL Implementation

## Host Program

The steps our host program takes can be broken down into four main sections.  To begin, the host program initializes opencl, this involves finding the Altera OpenCL platform as well as finding devices to run on.  For us, the only device being used is an emulated device.  Next a context is created and the binary file of our device code is loaded.  From there we attempt to build our program.  Next we initialize all of our buffers.  For this problem there are 8 buffers total.  They are the input, temp, w1, b1, w2, b2, w3, b3, and output buffers.  Each buffer is allocated a specific size that they will need.  

Next, the data is loaded in.  This involves parsing data from csv files.  The input data is loaded along with the weights and biases for each layer.  Validation data is also loaded.

Next, we run our program.  This involves enqueuing write buffers for each of our defined buffers and passing them data to use.  Afterwards we set our kernels arguments.  We launch our device and then wait for it to finish. We then read from the output buffer.  We compare our output to the validation data.
Finally, memory is freed and we release our program and context.

## Kernel Code

Due to the fact that the OpenCL kernel does not need to train the model, the kernel simply needs to perform simple multiplication and addition in order to find the values of each node and eventually produce an output. In order to parallelize this process, calculations that can be done in parallel needed to be identified. Since each layer is dependent on the previous one, all parallelization needs to take place on a single layer at a time, with a barrier after its completion so it is ensured that a previous layer is complete before computing the next.

<p align="center">
<img src="https://imgur.com/452tQ3r.png">
</p>

There are many different ways to parallelize the calculations on a single layer, however we chose to assign each thread a certain node on the target layer and calculate its value based on the values of the previous layer and the associated weights and biases. In addition to this, these calculations can be performed on multiple images at the same time and each thread does not need to necessarily work on a single image. This requires some simple math in order for a thread to determine the correct weights, biases, and previous node values in order to calculate the target node value, however this allows the maximum number of effective threads to increase along with the number of images being processed by the network.

## Timing Issues

Although the purpose of this lab was to test different numbers of threads on the execution time of our kernel program, the opposite expected effect occurred due to the fact that OpenCL was being run in an emulator. Because of this, instead of becoming faster through the use of parallelization, the execution time actually increased due to more threads generating too much overhead for the emulator.
